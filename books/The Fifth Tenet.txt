Sermon Date: September 20th, 2020
Introduction 
	British-Indian novelist Salman Rushdie once said in a presentation that “the moment you declare a set of ideas to be immune from criticism, satire, derision, or contempt, freedom of thought becomes impossible” (Krasicki 2007). In the modern world, people are subjected to endless torrents of partisan rhetoric. Dogmatism is so all-pervading that it permeates even the most arbitrary and private aspects of life with enough force to send nations to war over a game of soccer (as in the case of El Salvador and Honduras), or cause a man to bite another’s finger off over a political disagreement (as in the case of the incident at the 2009 Obamacare rally) (Lockhurst 2019; Malcom 2009). It can be heard in the impassioned slants against presidential candidates in the 2020 elections, in the fervent sermons of zealots and politicians who swear that they alone know the way to salvation, and even among friends who mean to persuade friends that they really do have the superior taste in aesthetics. It could seem at first quite simple to excuse oneself of the dogmatic ramblings rampant in pop-culture and the like, but the burden of dogma may not be such an easy burden to shake. Modern psychological research accounts for the inherent bias of human reasoning in the problem of belief, the importance of reliable belief -forming methods, and keys to overcoming unreliable belief-forming methods.  
	Intuitionism 
	When discussing the relationship between the will and the intellect, there is one central metaphor which immediately distinguishes itself from the rest in its broad explanatory power: That of “the strong blind man who carries on his shoulders the lame man who can see” (Schopenhauer 409). Such a metaphor is best explained through the social intuitionist model of moral judgment, which states that “intuitions come first and reasoning is usually produced after a judgement is made, in order to influence other people,” or to account for judgements by “ex post rationalizations” (Haidt 47; Magolis 21). One may understand intuitions as the subconscious, underlying emotional responses to stimuli which “can occur without extensive perceptual and cognitive encoding” (Zajonc 1). A study by Robert Zajonc in 1980 confirmed the affective primacy hypothesis, demonstrating that affective (intuitive) responses are made more quickly than rational responses, and with much more confidence. In fact, intuitive influence so strongly affects perception that it is not uncommon for an individual to have already decided whether or not he or she likes something before they have even begun to process what it is (Haidt 53). In reference to Schopenhauer’s metaphor, one may draw connections between intuition and the blind, strong man, who walks wherever he sees fit. Rational decision making is analogous to the lame, sighted man, who subsequently acts as a spokesperson for the blind man, defending his actions, or in rare cases, convincing him to walk the other way. One may take the following story as an example: 
	A family’s dog was killed by a car in front of their house. They had heard that dog meat 
was delicious, so they cut up the dog’s body and cooked it and ate it for dinner. Nobody 
saw them do this. 
In a study by moral psychologist Jonathan Haidt, 1620 volunteers were given this very short story among others to produce a kind of moral dumbfounding. Haidt had been careful to phrase the stories such that no character was harmed, but a social taboo had been violated. To his surprise, as many as 38% of the 1620 formulated reasons (some of which were entirely unrelated to the violated taboo) which would imply that the action was wrong because there was a victim (Haidt 30). For instance, some people claimed that the family would be harmed from eating dog meat, or that neighbors would be harmed from viewing the process, even though the story ruled both of those out by cooking and isolation. One may be inclined to ask oneself, “Were people really condemning the actions because they foresaw harms, or was it the reverse process--were people inventing harms because they had already condemned the action” (Haidt 30)? In the case of the latter, the results would reflect Zajonc’s conclusions that affective judgment is made much more quickly than conscious reason, and with more conviction. As Haidt expected, the judgment came rather quickly, but the justification was slow, painstaking, and sometimes apologetic. Intuition comes first, and reason comes later as a means of justifying the intuition. 
Further experimentation (bring in or leave out depending on time): 
Psychologists sometimes ask people to perform tasks while carrying a high cognitive load in order to distinguish controlled thinking (conscious) from automatic processes. If subjects have difficulty performing the task while carrying the load, one may conclude that controlled thinking is necessary to the task. Haidt found that cognitive load made no difference in judgmental ability compared to those who were asked to make judgments without cognitive load, suggesting that moral reasoning happens as a result of automatic processes. Haidt 30 
Joshua Greene/Jonathan Cohen brought 18 students to an fMRI scanner and presented stories with certain moral connotations. Students were asked to make judgments of whether or not the actions taken were morally correct. The areas of the brain involved in emotional processing and risk/reward activated consistently as the students made the decisions. Haidt 61 
Such is the first reason that humans strongly cling to their held dogmas with or without sufficient justification. Scottish philosopher David Hume aptly predicted such intuitional dogmatism when he declared that in the case of an argument “reasoning is not the source, whence either disputant derives his tenets; [thus] it is in vain to expect, that any logic, which speaks not to the affections, will ever engage him to embrace sounder principles” (Hume 3). 
Groupishness 
Because of the problem of intuition, many beliefs are held onto because of underlying moral and emotional assumptions, which serve to increase the divide between groups of people with different moral identities (Boghossian 39). The justification may look similar to this: 
“Jon believes good people believe X. Jon believes he’s a good person, so Jon believes he 
should believe X. Jon looks for evidence to support X and tends to believe X as a result, 
while believing he believes X based on the evidence he has found” (Boghossian 33). 
To better understand the problem of intuition, one may consult the biopsychosocial model, which shows that intuitions are influenced by psychological and social factors, which are influenced by biological and environmental factors (PsycholoGenie n.d.). One reason for the high level of social influence in the matter of intuition is explained through Hamilton’s Rule as a mechanism behind social evolution. Hamilton’s rule explains how kin selection promotes altruistic behavior among competing groups (e.g. herds, prides, tribes, etc.) to maximize the health of the group (Bourke 2014). “In most cases,” one study writes, “altruism is under positive selection via indirect fitness benefits that exceed direct fitness costs and social behaviour commonly generates indirect benefits by enhancing the productivity or survivorship of kin” (Bourke 2014). However, altruism is only specific to an individual’s kin; his perceived social allies. 
From a biological standpoint, scientists have observed chimpanzees raiding territories of rival groups, attempting to rape, kill, and steal from their competitors. Scientists deduce that “For millions of years, therefore, our ancestors have faced the adaptive challenge of forming and maintaining coalitions that could fend off challenges from rival groups” (Haidt 116). Just as Darwin wrote in The Descent of Man, such tribal groups in competition with each other would be more likely to survive and reproduce if individuals worked together to form more cohesive, efficient units (Darwin 362). As a result, an individual’s intuition is likely to be profoundly partial to ingroups, and unjustly biased against outgroups: the first instinct of tribalism. 
Hamilton’s rule makes sense in light of Mark Leary’s more recent findings that “the sociometer operates at a nonconscious and preattentive level to scan the social environment for any and all conditions that one’s relational value is low or declining” (Leary 85). Essentially, people are obsessed with the way that they are perceived within their own groups, whether or not they are aware that this is the case. Following the idea of the preattentive sociometer, it becomes easy to understand that people behave and believe in ways which maintain their relationships within social hierarchies as they understand them (Leary 85). Reason evolved as a way to justify social behaviors rather than to reflect the truth, so people are naturally dogmatic (Haidt 117). 
Significance 
Just as the metaphor of the blind giant and the sighted lame man breathes life into the social intuitionist model of moral judgment, so the fifth tenet of The Satanic Temple serves as a central axiom to the struggle against intuition: “Beliefs should conform to one’s best scientific understanding of the world. One should take care never to distort scientific facts to fit one’s beliefs.” 
Right away, one might see the conflict between the fifth tenet and human nature. People have not evolved to be objective. And some will argue that reason is nothing without intuition. In Descartes’ Error, for example, Antonio Damasio studies behavioral abnormalities in patients who suffered damage to the ventromedial prefrontal cortex (Damasio 1994). The patients lost all capacity for affect; for emotion, and thus, they could not rely on intuition to guide any decision. For all decisions that the patients made, each had to be closely examined by reason in an endeavor consuming considerable time and energy in order to be effective without the guiding affect. Neither having the will to examine decisions, nor the affect to default on, the patients began to lose their jobs and their relationships, and their social IQs dropped to zero. One may infer that not only is social identity a rationalization of intuitions based on perceived social roles, but it is also a model of group-consciousness that can evolve into increasingly complex meaning-making matrices (Abes 3-4). Therefore, no emotion in decision making means no meaning, and poorer decisions. 
However, even though emotion is necessary for physical and social survival when immediate decisions are required, it is still not always accurate, and it makes people more susceptible to dogmatic, partisan thought patterns. Peter Boghossian writes in his 2019 book, How to Have Impossible Conversations, that the repercussions of the lack of open, critical thought in a deeply polarized world are vast and detrimental (Boghossian 8). I have made an attempt to prove that humans are wired to rely on unreliable epistemologies to arrive at an enormous array of false beliefs, but I must now make the case that false beliefs lead to harmful results. 
I have endeavored to make three proofs in syllogistic form by inductive reasoning. I have constructed the following arguments to demonstrate that having fewer justified, rational beliefs can mislead people in unfavorable ways: 
1. The argument from efficacy comes from the statistical probability of achieving an intended goal with and without unfounded beliefs. 
a. One’s beliefs strongly influence one’s behavior, expectations, and other beliefs. 
b. Thus, a person with fewer justified beliefs is likely to behave in response to a greater amount of things that do not correspond to reality (which are false expectations and beliefs) (from p1). 
i. For instance, a lapse between a target’s perceived position and its actual position is likely to cause an archer’s arrow to miss. There are many more ways to miss a target than to hit a target (third law of thermodynamics). 
c. A person with fewer justified beliefs is more likely to spend time and energy in response to things that are untrue (from p2). 
d. So living by ill-informed or unjustified beliefs leads to a life without efficacy in intended areas, especially those directly affected by such beliefs (from p3). 
2. The argument from longevity comes from an individual’s improved efficacy in manipulating the environment to his own benefit according to a justified belief. 
a. An individual can to an extent manipulate oneself or one’s environment more effectively in response to a reliable causal relationship between a stimulus and the corresponding belief (from argument from efficacy). 
i. For instance, a prey species is able to more effectively avoid being eaten if it is justly aware of a predator’s presence than if it is unaware. 
b. Efficacy gives an individual control over his environment in areas affected by such (from p1). 
c. Unjustified beliefs thereby remove control from the party in question and give it to the environment or any other party ready to receive it (from p2). 
d. Thus, the life guided by unjustified belief, having lost control over its environment, makes itself more susceptible to harm, increasing its likelihood to perish sooner (all else equal) (from p3). 
3. The argument from ethics comes from an individual’s improved efficacy in manipulating the environment to the benefit of others according to a justified belief. 
a. An individual’s behavior and expectations are strongly influenced by belief. 
b. An individual’s behavior and expectations can influence other people and the environment (from p1). 
i. Remember that unjustified beliefs are likely to harm an individual in terms of efficacy and longevity (from conclusions 1 & 2). 
c. So unjustified beliefs are likely to harm other people and groups outside of the individual (from p2). 
So why do we strive to have true beliefs? Are there any moral implications? 
The choice to live by ill-informed or unjustified beliefs is a breach in responsibility synonymous with supporting any present injustice (or one implied by said beliefs) to any party (oneself or others) affected by such an injustice (Q1, Q2, Q3). 
One has a moral and logical obligation to make an effort to hold justified beliefs, starting with the areas most likely to affect an individual’s or group’s life in the most significant ways. 
Possible Solutions 
Evolution has not finished its job, and people are trapped in an unfortunate predicament. On the one hand, they are unreasonable and incredibly groupish, but on the other, they have a responsibility to be objective. The question arises: How are people to deal with the problem of psychological bias in the search for objectivity? 
The first of two ways focuses inward. Sociologist Elisa Abes studies social identity perception among lesbian college students at Miami University in her essay, “Reconceptualizing the Model of Multiple Dimensions of Identity: The Role of Meaning-Making Capacity in the Construction of Multiple Identities” (Abes 2007). It is evident that the women in the Abes and Jones study who were unable to overcome social influence in self-authorship were simply not aware of it, or were aware of it but still behaving in response to it (as in the case of one woman, who unknowingly gave up her control to social groups by virtue of her unwavering opposition to them) (Abes 8). Conversely, those who developed foundational social identities were better able to recognize their own groups, understand the influence of those groups on their outlooks, and respond to that influence accordingly. The results of Abes’ studies imply that unwanted social influence can be overcome through the awareness of contextual relationships, or “the ability to engage in relationships without losing one’s internal identity” (Abes 5). More simply put, the first step in avoiding bias is to recognize one’s susceptibility to it, and the areas in which that susceptibility is most salient. 
After understanding one’s own potential for error, it may become clear that the mere assumption of one’s own correctness is not adequate as a way of knowing anything. Karl Popper, a prolific Austrian philosopher, proposed a new theory of epistemology in science called falsification theory. Popper states in The Logic of Scientific Discovery that “Insofar as a scientific statement speaks about reality, it must be falsifiable: and insofar as it is not falsifiable, it does not speak about reality” (Popper 2005). That is, unless there is specific, reasonable criteria under which a statement can be disconfirmed, the reality of such a statement cannot be justified. An example to which I frequently return is my belief in evolution. If my belief in evolution was not falsifiable, then there would be no way for me to figure out if I was mistaken. If evidence has no power to sway a belief, that belief cannot be based on evidence (Boghossian 2019). “The point is,” says Popper, “that, whenever we propose a solution to a problem, we ought to try as hard as we can to overthrow our solution, rather than defend it” (Popper 2005). Such is the way that the scientific method became so reliable. 
One of the best known ways to use falsificationism in one’s own strongly held beliefs is to practice synthesis. Synthesis is a five step process in which a person presents an idea (sometimes to himself); invites or synthesizes counterarguments; employs those counterarguments to find specific, reasonable criterion for disconfirming the idea, and refines the belief if necessary. The final step is repetition with the modified idea (Boghossian 77). It is most beneficial (albeit most difficult) to perform synthesis with a deeply held or controversial belief. 
The second way is the promotion of external change. The social change model is similar to intuitionism insofar as it posits that group values affect individual values, which sometimes affect group values again in turn. However, the social change model makes a clear distinction between group values and societal values (Wagner 8). Individualistic, group, and societal values all influence each other, but possibly to varying degrees. One can deduce that if the three systems are interrelated, a positive change in one level can lead to positive changes in others. As an example, a leader may focus his influence on a single group rather than an entire society so that his leadership is more effectively marketed to certain people than it would be in a more general approach. If his influence serves to fight racism in a single group, then each individual in the group will be affected, and a portion of society will ultimately be affected by his leadership. 
Street epistemology (SE) is a useful application of social change on an individual level. The technique was originally introduced in A Manual for Creating Atheists to challenge popular religious ideas, but it has since been adapted for a more productive and generalized approach (Boghossian 2013, 2019). Peter Boghossian writes in How to Have Impossible Conversations that SE is a tool for effective communication “with people who hold radically different beliefs” (Boghossian 2019). He goes on to write about SE as a method for managing conversations that explore the reliability of underlying assumptions through Socratic dialogue to introduce doubt in unfair belief-forming methods. This tool circumnavigates the backfire effect (which can be caused by social intuitions or poorly thought out identity constructions) by allowing the interlocutor to form their own conclusions (Boghossian 2019). The intended result is mutual understanding and critical thinking. 
Conclusion 
There is a wealth of literature on the biased nature of human rationale, which can only be overcome with deliberateness and understanding. Reason is the sighted man on the blind man’s shoulders, and the consequences of the blind man, while sometimes necessary, are dire. Science, social understanding, synthesis, and street epistemology are all at the forefront of overcoming intuition in the war between irrationality and the need for reason. I leave you with a quote.
“Affective reactions to stimuli are often the very first reactions of the organism, and for lower organisms they are the dominant reactions.” Do not be a lower organism. Be a Satanist.
So it is done. Hail Satan. 